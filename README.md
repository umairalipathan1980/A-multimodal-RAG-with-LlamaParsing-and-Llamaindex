# A multimodal RAG with LlamaParse and Llamaindex
This code uses OpenAI's multimodal model gpt-4o-mini for image understanding and generating final RAG response. For creating text and image embeddings, Llamaindex's embedding model is used.
The extracted images from the documents are stored in "images" directory.  
An example PDF is given to test the code.
